---
title: 'Can Crime Rates be Reduced by a Tougher Criminal Justice System?'
subtitle: 'MIDS W203, Fall 2018, Lab 3'
author: 'Duda Espindola, Pri Nonis, Laura Pintos, Payman Roghani'
output:
    prettydoc::html_pretty:
        theme: tactile
        highlight: github
        toc: true
        number_sections: true
---
<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
source('assets/utility.R')

import('knitr')
import('kableExtra')
import('tidyverse')
import('RColorBrewer')
import('ggthemes')
import('stargazer')
import('lmtest')
import('maps')
import('formattable')
import('sparkline')
import('cowplot')
import('corrplot')
import('ggfortify')
import('GGally')

options(digit = 2, warn = -1)
```

# Introduction and Research Question

The primary motivation of this report is to provide causal estimates for determinants of crime in the state of North Carolina. The main aim of our study is to shape the public policy platforms of the political campaign that has hired our services, in the upcoming election cycle. We strive to provide actionable policy recommendations through motivated data analysis of the research question(s).

Our research focuses on the following specific question: <b>Can crime rates be reduced by a tougher criminal justice system?</b> We explore how certainty of punishment and severity of punishment within the criminal justice system affects crime. As one of the key goals of the political campaign is to reduce the crime rate, the natural choice for the outcome variable of our study is the Crime Rate variable. We seek to explain the variability of this variable using Probability of Arrests, Probability of Conviction, and Probability of Prison.

$$
\begin{aligned}
\textbf{Crime Rate} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison}
\end{aligned}
$$

We will primarily use these three explanatory variables as proxies to measure the effects of the the criminal justice system on crime and this relationship will be explored in our first OLS model. However, we expect other variables to have significant secondary effects on this relationship and thus, will further explore their impact in our extended second OLS model.

## Policy Hypothesis

The null hypothesis assumes that the outcome Crime Rate variable is not impacted by the three explanatory variables, Probability of Arrest, Probability of Conviction, and Probability of Prison. We will test the following hypothesis through our detailed data analysis to justify our ultimate policy recommendation(s).

+ <b>Increasing arrest rates will decrease crime rate</b>
+ <b>Increasing conviction rates will decrease crime rate</b>
+ <b>Increasing prison verdicts will decrease crime rate</b>

Our recommendations will be based on sound statistically significant and practically significant results. We hope to reject the null hypothesis by sufficiently explaining the variability of Crime Rate by our explanatory variables. 

# Data Loading and Cleaning

The primary data source for our study is **Cornwell and W. Trumball (1994), Estimating the Economic Model of Crime with Panel Data, Review of Economics and Statistics 76, 360-366**. We will use a single cross-section of data for **1987** from the multi-year panel. (The authors used panel data methods and instrumental variables to control for some types of omitted variables)

The dataset is provided for the year **1987** except for the **Percent Minority** (pctmin), which is provided for 1980.

## Basic Sanity Checks

The dataset contained several technical defects such (1) as empty rows, (2) a duplicated row, and (3) a typo that prevented a numeric variable from being loaded correctly. These issues were easily corrected as shown below.

```{r loading_and_fix}
crime           <- read.csv('crime_v2.csv') # load the dataset
rownames(crime) <- NULL                     # remove row names

crime           <- na.omit(crime)                          # (1) remove empty rows
crime           <- crime[!duplicated(crime$county),]       # (2) remove duplicated row
crime$prbconv   <- as.numeric(as.character(crime$prbconv)) # (3) fix non-numeric value

dim(crime)
```

From the 100 counties of North Carolina our data-set contain a sample of **90** counties. The map below shows the Crime Rate per Capita for the 90 observations; the 10 counties that are not present in the dataset is shown in gray. The dataset contains **25** variables covering the following aspects.

```{r crime_map, fig.height = 4.5, fig.align = 'center', warning = FALSE}
mSetup(); mMapNC('crmrte', 'Crime Rate per Capita')
```

The missing counties appear to be geographically diverse and gives no reason to suspect the sample quality in terms of randomness, at least with respect to geographical clustering.

## Deeper Analysis

We had to address various anomalies in the dataset, confirming if the values made sense based on the code key and understanding the outlying data points. We used a custom summary table to gleam a high level overview of the data for further analysis. We sorted the variables into four categories as follows.

```{r summary, warning = FALSE}
crime.summary <- sBuild(crime, crime$crmrte)
```

<b>Variable Categories</b>

+ <b>Identification</b>
```{r var_1, results="asis"}
sTable(crime.summary[c(1,2),]) # Identification
```

+ <b>Crime & Law Enforcement</b>
```{r var_2, results="asis"}
sTable(crime.summary[c(3,4,5,6,7,8,25),]) # Crime & Law Enforcement
```
+ <b>Demographics & Geography</b>
```{r var_3, results="asis"}
sTable(crime.summary[c(9,10,11,12,13,14,25),]) # Demographics & Geography
```
+ <b>Weekly Wages</b>
```{r var4, results="asis"}
sTable(crime.summary[c(15,16,17,18,19,20,21,22,23),]) # Weekly Wages
```

### Probabilities Above 1

Theoretically speaking, we should not have probabilities over 1 (100%), but that is what we observe in variables Probability of Arrest (prbarr) and Probability of Conviction (prbconv). However, when we understand how those variables were proxied, we realize that they are not actual probabilities: they are simply ratios. 

The probability of arrest is proxied by the ratio between the number of arrests in 1987 to the number of offenses in 1987. However, not every arrest made in 1987 might be referring to offenses made in 1987: there might be arrests referring to crimes committed in previous years, which explains why the ratio between arrests and offenses in 1987 could be above 1.

The probability of conviction is proxied by the ratio between the number of convictions and to the number of arrests in 1987. It is the same thing we have observed for the probability of arrest. The convictions issued in 1987 are not all necessarily referring to arrests made in 1987. Besides that, one arrest might lead to several convictions (example, a person arrested might be convicted for several crimes). In that sense, it is possible for us to have this variable achieving values above 1.

### Outliers Off by Order of Magnitude

Another anomaly we observed, both by the histogram and by the summary statistics, is that for the density variable. There was a single value that is several orders of magnitude lower than other all other observations, with a density of 0.00002. We decided to investigate this further by using third party data sources.

```{r density_check}
crime$county[crime$density<0.0001]
```

Searching for the FIPS code of this county (173), we see that it is Swain County. When we search the data for Swain County in 1987 in the United States Census Bureau database, we see that the density was in fact 0.0202. That is clearly an arithmetic error, generating a value a 1000 times smaller. Therefore, we corrected it as shown below.

```{r density_fix}
crime$density[crime$county==173]<- crime$density[crime$county==173] * 1000
crime$density[crime$county==173]
```

### Other Significant Outliers

For the Service Industry Weekly Wages, there is one value that stands out as is significantly larger than the next largest value.

```{r service_check}
crime$county[crime$wser>2000]
```

Searching for the FIPS code of this county (185), we see that it is Warren County. Coincidently only the service sector wages appear to be inflated for this county compared to the average weekly wages of all sectors across North Carolina. It is very likely this value was incorrectly multiplied by 10, and the actual value is 217.7 instead of 2177.1. However, since we cannot confirm that with certainty, we will leave it unmodified and not discard the observation.

# Model Building Process

```{r options, echo = FALSE}
options(digits = 2)
```

The study of the research question requires some exploratory data analysis to choose the correct variables that identify the true relationship we are trying to model. The section below details the process of defining the models.

## Selection of the Outcome Variable

Crime rate is our dependent variable; therefore, we need to conduct additional exploratory data analysis on this variable, besides the steps taken in our general EDA above.  

In our initial exploration, we noticed that the crime rate histogram showed a positively skewed distribution. A log transformation of the variable pulls the outlying data points closer to the bulk of the observations, resulting in a normal distribution.

```{r outcome_plot, fig.align = 'center', warning = FALSE}
p1 <- pHist(    crime$crmrte , breaks = 20, label = "Crime Rate"      )
p2 <- pHist(log(crime$crmrte), breaks = 20, label = "Crime Rate (log)")

plot_grid(p1, p2)
```

More importantly, the log transformation will allow us to interpret changes in the dependent variable as percentages, which is a more meaningful way to describe such changes in this context. Counties have different crime rates and percentage changes in crime will enable county-to-county comparison. As such, we implemented a log transformation on this variable. 

```{r outcome_trans}
crime$crmrte.log <- log(crime$crmrte) # log transformation
```

There is an extreme outlier on the left tail of the data, but we decided to keep that as we don’t have a strong reason for removing it.

## Explanatory Variables, Base Model

As explained in the introduction, in order to test our hypothesis regarding the impact of a tougher criminal justice system on crime rate, we are using 3 explanatory variables in our base model:

- Probability of Arrest: Defined as the ratio of offenses to arrests. Using this variable, we would like to assess the hypothesis that more stringent arrest protocols and improvements in crime detection would lead to lower crime rate.
- Probability of Conviction: Defined as the ratio of convictions to arrests. If our hypothesis regarding a negative impact of higher convictions/arrests ratio on crime rate is true, then this could lead to highly actionable measures. For instance, stricter sentencing guidelines could implemented, followed by allocation of more resources to law enforcement agencies to collect more effective evidence.
- Probability of Prison: Higher imprisonment rate, as one of the harshest types of criminal sentencing, could have a deterrent effect, leading to lower crime rate. Hence our interest in this variable. 

Looking at the summary statistics of the 3 variables, we don’t see any alarming issues. Also, histograms show a fairly normal distribution for all 3 variables. Although, there is 1 extreme outlier in `prbarr` and one in `prbarr` (which are both from the same observation, county 115) we decided to keep them in our data because we don’t have any reason to believe that they are erroneous values. That said, we will evaluate the influence of these extreme point during or diagnostic analysis of regression models. 

County 115 consistently shows up in the histograms of crime rate, prbarr and prbconv as an extreme outlier. It has a low density (below first quartile), which could be the reason for the unusual values  in our variables of interest.

```{r m1_explanatory_plot, fig.align = 'center', warning = FALSE}
p1 <- pHist(crime$prbarr,  breaks = 40, label = "Probability of Arrest"    )
p2 <- pHist(crime$prbconv, breaks = 40, label = "Probability of Conviction")
p3 <- pHist(crime$prbpris, breaks = 40, label = "Probability of Prison"    )

plot_grid(p1, p2, p3) # TODO : make three columns
```

Next, we looked at the scatterplots of dependent and explanatory variables for our base model. `prbarr`  seems to have a pretty linear relationship with `crmrte.log`. The same with `prbconv`, although we see a curvature towards the right side of the chart. 
`prbpris` does not seem to have a linear relationship with `crmrte.log`, based on the scatterplot; it looks more like a quadratic relationship. However, we decided to leave `prbpris` as is, because a quadratic transformation would make the interpretation of our model unnecessarily complicated. 

```{r m1_correlation, fig.align = "center", warnings = FALSE}
ggscatmat(crime, columns = c(26,4,5,6)) + geom_smooth(method = "lm") + theme_economist()
```

## Explanatory Variables, Extended Model

For Model 2, we decided to add two additional explanatory variables to our model.

- Avg. Sentence, Days (`avgsen`): We believe that longer prison sentences could have a greater deterrent effect in the community, leading to lower crime rate.

- Police per Capita(`polpc`): We chose this covariate based on the assumption that a higher number of cops in charge would mean an unsafe environment for individuals to commit crimes, which in turn builds a safer community. 

Having seen positive skewness in the distributions of both `avgsen` and `polpc` in our in initial EDA, we compared the histograms of these 2 variables in the original form and after log transformation. Since the log transformation results in a distribution closer to normal for both variables, we decided to use log transformations in our model. 

The outiler observed in these histograms are values from county 115. The low density of county 115 could explain why it is an outlier, the average sentence variable could be  very sensitive to violent crimes in a low density county.

```{r m2_explanatory_plot, fig.align = "center", warnings = FALSE}
p1 <- pHist(    crime$polpc  , breaks = 20, label = "Police per Capita"         )
p2 <- pHist(log(crime$polpc) , breaks = 20, label = "Police per Capita (log)"   )
p3 <- pHist(    crime$avgsen , breaks = 20, label = "Avg. Prison Sentence"      )
p4 <- pHist(log(crime$avgsen), breaks = 20, label = "Avg. Prison Sentence (log)")

plot_grid(p1,p2,p3,p4)
```

```{r m2_explanatory_transform}
crime$avgsen.log <- log(crime$avgsen) # log transformation
crime$polpc.log  <- log(crime$polpc ) # log transformation
```

Looking at the scatterplots of dependent and the additional explanatory variables for our second model. None of the additional variables seem to have a perfect linear relationship with the independet variable. But since we have already implemented a log transformation and seen improvment in variable distributions, we will not take additional steps to modify our variables and use them in their current state.

```{r m2_correlation, fig.align = "center", warnings = FALSE}
ggscatmat(crime, columns = c(26,27,28)) + geom_smooth(method = "lm") + theme_economist()
```

## Explanatory Variables, Kitchen-sink Model

Finally, we are adding almost other variables (except for `county` and `year`) to our 3rd model to compare with the other two. The exploratory data analysis for all these variable is included in Data Loading and Cleaning section of this report. 

The only additional step we took for Model 3, was evaluation of variable `mix` due to the positive skewness that we observed in its distribution. Here we are comparing the distribution of `mix` before and after log transformation, and since the distribution post log transformation looks fairly normal, we decided to use it in our Model 3.

```{r m3_explnatory_plot, fig.align = "center", warnings = FALSE}
p1 <- pHist(    crime$mix , breaks = 20, label = "Offense Mix"      )
p2 <- pHist(log(crime$mix), breaks = 20, label = "Offense Mix (log)")

plot_grid(p1, p2)
```

```{r m3_explanatory_transform}
crime$mix.log <- log(crime$mix) # log transformation
```

# Regression Models

We would like to address our key research question to understand whether strict criminal laws and their enforement result in lower crime rate. 

## Base Model

Based on the variables selected, our base population model is:

$$
\begin{aligned}
\textbf{log(Crime Rate)} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison} \\
           & + \textbf{u}
\end{aligned}
$$

```{r m1}
m1 <- lm(crmrte.log ~ prbarr + prbconv + prbpris, data = crime)
```

### Coefficients - M1

While holding all other covariates and ubobserved factors fixed:

- $\beta_0$ : `intercept` is -2.6846, which can not be interpreted in a meaningful way without considering other coefficients
- $\beta_1$ : `prbarr`    is -1.9992, which means we could predict that for every 0.01 increase in probability of arrest, crime rate will go down by approximately 1.99%
- $\beta_2$ : `prbconv`   is -0.7364, which means we could predict that for every 0.01 increase in probability of conviction, crime rate will go down by approximately 0.74%
- $\beta_3$ : `prbpris`   is 0.388, which means that every 0.01 increase in probability of prison is associated with a 0.39% increase in crime rate

It is worth noting that the coefficients for `prbarr` and `prbconv` amplify the effect of increasing `prbarr` or `prbconv`. This is not true for the coefficient of `prbpris`.

### Goodness of Fit - M1

* The R-squared value for the base model is <b>`r summary(m1)$r.squared`</b>, which means around 45% of the variation in crime rate could be explained by our model.
* The Akaike Information Criterion value for the base model is <b>`r AIC(m1)`</b>, which we will compare with those of the next models to evaluate goodness of fit.

### 6 CLM Assumptions - M1

1. Linearity: Our model is linear in parameters as shown above
2. IID Sampling: We don’t have sufficient insight into how the data have been collected. For example, we don’t know if the probability of arrest is calculated by dividing the number of all arrests by the number all crimes across counties in 1987, or from a sample. But since the data are collected by key government agencies and used for analysis by reputable researchers, we assume random sampling. Another issue is that we don’t have data from some of counties and we are not sure how including additional data from those counties would affect our analysis. As a result, the insights from our regression modelling might not be applicable for the entire North Carolina, unless we have full insight into the missing data.  An additional concern that we have with the sampling is that the data we have is only for year 1987. This specific year is know for the biggest  crash in the stock market in one single day.  If this event created specific conditions like an abnormal number of crime offenses (i.e. due to poverty, depression, anger, etc.) our sample is biased.
3. Multicollinearity: We didn’t see any sign of perfect collinearity among our explanatory variables. In addition, R would warn users if such collinearity exists, which did not happen throughout our analysis.
4. Zero Conditional Mean: We will cover that below.
5. Homoskedasticity: See below.
6. Normality: See below.

### Model Diagnostics - M1

```{r m1_residuals, fig.align = 'center'}
pHist(m1$residuals, breaks = 20, label = "Residuals")
```

<b>Residuals Plot</b>
</br>
The histogram of residuals show a fairly normal distribution where the bulk of the data points are (except for a few spikes that don’t look totally abnormal). However, we could see the extreme outlier on the left that creates some sort of negative skew in the distribution. 

```{r m1_diagnostics, fig.align = 'center'}
autoplot(m1) + theme_economist()
```

<b>Residual vs Fitted</b>
<br/>
The residual vs fitted spline shows curvatures, deviating from zero, both on the left and the right side. The one on the left is the result of extreme outlier that we observed before. The curvature on the right side, as the `crmrte.log` increases, might be because we don’t have enough data points. Either way, this chart doesn’t provide the confidence to verify the zero mean condition assumption.

<b>Normal Q-Q</b>
<br/>
Most points are on, or fairly close to the diagonal line, based on which we can tell that the residuals are distributed normally. However, we see a little bit of deviation towards the two ends of the line. Thus, we will take additional steps to verify this assumption. 

<b>Scale-Location</b>
<br/>
Despite the fact that points on chart seem to spread out as we move to the right, there is not strong sign of heteroskedasticity, since we have very few points on the left side.

<b>Residuals vs Leverage</b>
<br/>
As suspected, the residual from observation row 51 (county 115), has a high influence on our model, with a Cook’s distance of about 1

<b>Breusch-Pagan Test</b>
<br/>
In order to evaluate CLM assumption 5 `homoskedasticity` the Breusch-Pagan test was used. As the result p-value <b>`r bptest(m1)$p.value`</b> was greater than 0.05 the null hypothesis (absence of heteroskedasticity) can not be rejected. In other words there is no heteroskedasticity in our model.

<b>Shapiro-Wilk Test</b>
<br/>
In order to evaluate CLM assumption 6 `normality` the Shapiro-Wilk test was used. As the result p-value <b>`r shapiro.test(m1$residuals)$p.value`</b> is greater than 0.05 the null hypothesis (that residuals are drawn from a population with normal distribution) can not be rejected. In other words the residuals in our model are normally distributed.

### Interpretation and Conclusion - M1

As evidenced by the coefficients or base model, we can state that increases in probability of arrest and probability of conviction could potentially lower crime rate. In other words, a policy focused on more stringent arrest protocols and stricter criminal sentencing could be proposed by the political campaign. 
The probability of prison has a positive coefficient in our base model, meaning a higher prison to conviction ratio is associated with higher crime rate. We don’t believe this relationship means that, for example, if we increase the probability of prison, the crime rate will go up. We think that this might be due to the fact that the prison to conviction ratio is already high in areas where crime rate is high. For a more effective assessment of such a relationship we need to have data to see the trends in crime rate before and after the prison to conviction rate goes up as a result of policy change, which is not currently included in our dataset.  An additional possible explanation is that incarceration does not deter crime as it exposes the prisoners to an environment which could amplify their criminal behaviour when they finish their sentence. 

## Extended Model

As explained in the Model Building Process section, we are adding 2 other covariates to out second model: Avg. Sentence, Days (`avgsen`) and Police per Capita(`polpc`). Not only these 2 variables could help us provide actionable recommendations to the political campaign, but also, we assumed, they are correlated with the 3 variables in the base model and thus make the model more accurate. 

$$
\begin{aligned}
\textbf{log(Crime Rate)} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison} \\
           & + \textbf{log(Average Sentence)} \\
           & + \textbf{log(Police per Capita)} \\
           & + \textbf{u}
\end{aligned}
$$

```{r m2}
m2 <- lm(crmrte.log ~ prbarr + prbconv + prbpris + avgsen.log + polpc.log, data = crime)
```

### Coefficients - M2

While holding all other covariates and ubobserved factors fixed:

- $\beta_0$ : `intercept`  is `r coef(m2)[1]`, which can not be interpreted in a meaningful way without considering the other coefficients
- $\beta_1$ : `prbarr`     is `r coef(m2)[2]`, we could predict that for every 0.01 increase in probability of arrest, crime rate will go down by approximately 2.35%
- $\beta_2$ : `prbconv`    is `r coef(m2)[3]`, we could predict that for every 0.01 increase in probability of conviction, crime rate will go down by approximately 0.73%
- $\beta_3$ : `prbpris`    is `r coef(m2)[4]`, we could predict that for every 0.01 increase in probability of prison is associated with a 0.39% increase in crime rate
- $\beta_4$ : `polpc.log`  is `r coef(m2)[5]`, we could predict that for every   1% increase in police per capita is associated with a 0.62% increase in crime rate
- $\beta_5$ : `avgsen.log` is `r coef(m2)[6]`, we could predict that for every   1% increase in avg. prison sentence, crime rate will go down by approximately 0.065%

### Goodness of Fit - M2

* The R-squared value is <b>`r summary(m2)$r.squared`</b>, which means around 61% of the variation in crime rate could be explained by our model. Even though this is a higher number compared to our base model, it doesn’t necessarily show a better fit because when we add variables R-squared goes up anyway. Because of this we look at the AIC value to compare the two models in terms of goodness of fit.
* The Akaike Information Criterion value is <b>`r AIC(m2)`</b>, which is lower than that of base model value `r AIC(m1)`. This confirms that the extended model is more accurate than the base model.

### 6 CLM Assumptions - M2

1. Linearity: Our model is linear in parameters.
2. IID Sampling: See our note for the base model. 
3. Multicollinearity: We didn’t see any sign of perfect collinearity among our explanatory variables. In addition, R would warn users if such collinearity exists, which did not happen throughout our analysis.
4. Zero Conditional Mean: We will cover that below.
5. Homoskedasticity: See below.
6. Normality: See below.

### Model Diagnostics - M2

```{r m2_residuals, fig.align = 'center'}
pHist(m2$residuals, breaks = 20, label = "Residuals")
```

<b>Residuals Plot</b>
</br>
The histogram of residuals show a fairly normal distribution (especially compared with the same plot for base model) where the bulk of the data points are. However, we could see the extreme outlier on the left that creates some sort of negative skew in the distribution. 

```{r m2_diagnostics, fig.align = 'center'}
autoplot(m2) + theme_economist()
```

<b>Residual vs Fitted</b>
<br/>
The residual vs fitted spline is much flatter than that of base model. However, it shows a curvature with positive slope on the right side, deviating from zero. This might be due to the fact that we don’t have enough data points.

<b>Normal Q-Q</b>
<br/>
Most points are on, or fairly close to the diagonal line. However, as in base model, we see some deviations towards the two extremes of the line. Thus, we will take additional steps to verify this assumption. 

<b>Scale-Location</b>
<br/>
Despite the fact that points on chart seem to spread out as we move to the right, there is not strong sign of heteroskedasticity, since we have very few points on the left side.

<b>Residuals vs Leverage</b>
<br/>
As in the base model, the residual from observation row 51 (county 115), has a high influence on our model. But in model 2, its Cook’s distance is much lower than what we saw in the base model.

<b>Breusch-Pagan Test</b>
<br/>
In order to evaluate CLM assumption 5 `homoskedasticity` the Breusch-Pagan test was used. As the result p-value <b>`r bptest(m2)$p.value`</b> was greater than 0.05 the null hypothesis (absence of heteroskedasticity) can not be rejected. In other words there is no heteroskedasticity in our model.

<b>Shapiro-Wilk Test</b>
<br/>
In order to evaluate CLM assumption 6 `normality` the Shapiro-Wilk test was used. As the result p-value <b>`r shapiro.test(m2$residuals)$p.value`</b> is smaller than 0.05 the null hypothesis (that residuals are drawn from a population with normal distribution) can be rejected. That said, given the sample size of >30 we can assume that the sampling distribution of our coefficients is normal, so assumption 6 (normality) still holds in our model.

### Interpretation and Conclusion - M2

As shown in the analysis above, our second model confirms what we found in our base model: increases in probability of arrest and probability of conviction could potentially lower crime rate. In other words, a policy focused on more stringent arrest protocols and stricter criminal sentencing could be proposed by the political campaign. Moreover, an increase in avg. prison sentence could lead to lower crime rate as explained above. This is another recommendation we plan to provide to the political campaign, a policy for longer prison time. 

As in the base model, the probability of prison has a positive coefficient in our base model, meaning a higher prison to conviction ratio is associated with higher crime rate. Also, in model 2, we found that increase in police per capita is associated with higher crime rate. We believe that the relationships we observed might be due to the fact that the prison to conviction ratio and police per capita are already high in areas where crime rate is high. As stated before, for a more effective assessment of this situation, we would have to have data to see the trends in crime rate before and after changes in prison/conviction ratio and police per capita where they are implemented. 

## Kitchen-sink Model

For the third model, we are adding to the second model the rest of  the variables in the dataset as predictors, with the exception of year and county.  With this approach we are not following a criteria for inclusion of a variable in the model (i.e. is the variable relevant or not in the context of our research question, does it have a confounding effect or not with the variables in the previous models) and we do not expect to obtain the most parsimonious model that describes our data.  This third model would probably be an overfitting model.

$$
\begin{aligned}
\textbf{log(Crime Rate)} & \sim \textbf{Everything} \\
           & + \textbf{u}
\end{aligned}
$$

```{r m3}
m3 <- lm(crmrte.log ~ prbarr + prbconv + prbpris + avgsen.log + polpc.log + mix.log +
             density + taxpc + west + central + urban + pctmin80 + pctymle +
             wcon + wtuc + wtrd + wfir + wser + wmfg + wfed + wsta +
             wloc, data = crime)
```

### Coefficients - M3

### Goodness of Fit - M3

* The R-squared value is <b>`r summary(m3)$r.squared`</b>, which means around 86% of the variation in crime rate could be explained by our third model. Even though this is a higher number compared to our previous models, it doesn’t necessarily show a better fit because as we add variables R-squared goes up anyway.
* The adjusted R-squared value is <b>`r summary(m3)$adj.r.squared`</b> (compared to an adjusted R-squared value of 0.59 for the second model). When comparing two models used to predict the same response variable, we generally prefer the model with the higher value of adjusted R2, however, we do not know if another specification model with less variables than the third model could have a higher adjusted R2.
* Akaike Information Criterion value is <b>`r AIC(m3)`</b> which is lower than the AIC value for base model `r AIC(m1)`, and the AIC value for our second model `r AIC(m1)`. The third model is more accurate according to this test but it is probably not the most parsimonious model.

### 6 CLM Assumptions - M3

1. Linearity: Our model is linear in parameters
2. IID Sampling: See our note for the base model
3. Multicollinearity: We didn’t see any sign of perfect collinearity among our independent variables. In addition, R would warn users if such collinearity exists, which did not happen throughout our analysis
Zero conditional mean: We will cover that in the next phase of the project
4. Homoscedasticity: see below
5. Normality: see below

### Model Diagnostics - M3

```{r m3_residuals, fig.align = 'center'}
pHist(m3$residuals, breaks = 20, label = "Residuals")
```

<b>Residuals Plot</b>
<br/>
The histogram of residuals show a fairly normal distribution.  However, we could see the extreme outlier on the left that creates some sort of negative skew in the distribution.

```{r m3_diaggnostics, fig.align = 'center'}
autoplot(m3) + theme_economist()
```

### Interpretation and Conclusion - M3

In addition to what we concluded for the previous models specifications, we could advise the political campaign, that given that an increase in density and in percent of young male potentially predict an increase in crime rate (see coefficients above), they should explore the possibility of defining outreach program specifically designed for this demographic group in urban settings.  In addition the campaign should not base their strategy for the outreach programs on percent of minorities in the counties.

## Regression Table

```{r regression, results = "asis"}
stargazer(m1, m2, m3, type = "html", report = "vc", title = "Linear Models of Crime Rate",
          keep.stat = c("rsq", "n"), omit.table.layout = "n")
```

*[placeholder: include commentary on practical significance of coefficients in the final report, once we've received peer feedback]*

# Omitted Variables Analysis

We have proposed to model the logarithm of the crime rate `log(crmrte)` as a linear combination of the probability of arrest `prbarr`, the probability of conviction `prbconv`, and the probability of prison `prbpris`.
<br/>

However, other variables might impact the Crime Rate<br/>

* Percent of Population with Registered Guns `guns`
* Average Years of Education `avgeduc`
* Unemployment Rates `unmprt`
* Percent of Population Below the Poverty Line `pctpov`

Based on this a more realistic model may look like the following.
$$
log(crmrte) = \beta_0 + \beta_1 \cdot prbarr + \beta_2 \cdot prbconv + \beta_3 \cdot prbpris + \beta_4 \cdot guns \\
+ \beta_5 \cdot avgeduc + \beta_6 \cdot unmprt + \beta_7 \cdot pvtpov + u
$$

Compared to the base model, build using the available data.

$$
log(crmrte) = \alpha_0 + \alpha_1 \cdot prbarr + \alpha_2 \cdot prbconv + \alpha_3 \cdot prbpris + w
$$

To assess the direction of the bias, we will do an analysis for each omitted variable.

## Percent of Population with Registered Guns

North Carolina has no law that requires the comprehensive registration of firearms throughout the state. However, the sheriff of each county must keep a record of all permits to purchase a handgun, including the name, date, place of residence, and age of each person to whom a permit is issued. We could reach out for this information for a more accurate representation, however, we will now focus on assessing the bias of this variable. First, we will write the `guns` variable as a linear combination of the variables we do have the data for:

$$
guns = \gamma_0 +\gamma_1 \cdot prbarr + \gamma_2 \cdot prbconv + \gamma_3 \cdot prbpris +v
$$

$\gamma_0$ represents the intercept. The other $\gamma_n$ will be the slope coefficient for each of the model variables. We can make some assumptions:

$\beta_4$ (the slope for the guns variable for crime rate) has a positive value: percent of people with registered guns will have a positive correlation with the crime rate (accidental gunshots, bad reactions in traffic, wrongly assuming risk)

$\gamma_1$ has a positive value: probability of arrest will have a positive correlation with the percentage of people with registered guns (it is easier to catch crimes commited with registered guns)

$\gamma_2$ has a positive value: probability of conviction will have a positive correlation with the percentage of people with registered guns (it is easier to convict with more evidence - registered gun)

$\gamma_3$ has a positive value: probability of prison will have a positive correlation with the percentage of people with registered guns (it is more likely to issue a sentence with prison time for crimes commited with a gun)

$\beta_4$ is positive, and so are $\gamma_1$, $\gamma_2$ and $\gamma_3$. So the ommited variable percent of population with registered guns bias will be positive for $prbarr$, $prbconv$ and $prbpris$.That means that:

$$
\alpha_1 > \beta_1 \\
\alpha_2 > \beta_2 \\
\alpha_3 > \beta_3 \\
$$

## Average Years of Education

That information can be obtained in census databases. For assessing the bias this variable has on the available ones, we must write $avgeduc$ as a linear combination of the variables we do have the data for:

$$
avgeduc = \gamma_0 +\gamma_1 \cdot prbarr + \gamma_2 \cdot prbconv + \gamma_3 \cdot prbpris +v
$$

$\gamma_0$ represents the intercept. The other $\gamma_n$ will be the slope coefficient for each of the model variables. We can make some assumptions:

$\beta_5$ (the slope for the avgeduc variable for crime rate) has a negative value: average years of education will have a negative correlation with the crime rate (more education leads to more tolerance and better understanding of the laws)

$\gamma_1$ has a positive value: probability of arrest will have a negative correlation with the average years of education (more educated people will take some extra precaution about getting caught)

$\gamma_2$ has a close to zero value: probability of conviction will have very low correlation with the average years of education (the conviction is related to the nature and the evidences for each crime, not the person commiting it, in a ideal world)

$\gamma_3$ has a close to zero value: probability of prison will have very low correlation with the average years of education (in a ideal world, the issuing of a sentence should be only related to the nature of the crime commited)

$\beta_5$ is negative, and so is $\gamma_1$, however, $\gamma_2$ and $\gamma_3$ are very close to zero. So the ommited variable average years of education bias will be positive for $prbarr$. That means that:

$$
\alpha_1 > \beta_1 \\
$$

## Unemployment Rates

That information can be obtained in census databases. For assessing the bias this variable has on the available ones, we must write $unmprt$ as a linear combination of the variables we do have the data for:

$$
unmprt = \gamma_0 +\gamma_1 \cdot prbarr + \gamma_2 \cdot prbconv + \gamma_3 \cdot prbpris +v
$$

$\gamma_0$ represents the intercept. The other $\gamma_n$ will be the slope coefficient for each of the model variables. We can make some assumptions:

$\beta_6$ (the slope for the umnprt variable for crime rate) has a positive value: unemployment rate will have a positive correlation with the crime rate (unemployment might lead to people seeking illegal forms of income)

$\gamma_1$ has a close to zero value: probability of arrest will have very low correlation with the unemployment rates (the arrest is related to the evidences available for the police to catch the criminal - in an ideal world)

$\gamma_2$ has a close to zero value: probability of conviction will have very low correlation with the unemployment rates (the conviction is related to the nature and the evidences for each crime, not the person commiting it, in a ideal world)

$\gamma_3$ has a positive value: probability of prison will have positive correlation with the unemployment rates (in a ideal world, the issuing of a sentence should be only related to the nature of the crime commited, however some judges might consider that an unemployed person is more likely to commit a crime again, as means of income, and would be more prone to issuing a sentence with prison time)

$\beta_6$ is positive, and so is $\gamma_3$, however, $\gamma_1$ and $\gamma_2$ are very close to zero. So the ommited variable unemployment rates bias will be positive for $prbconv$. That means that:

$$
\alpha_3 > \beta_3 \\
$$

## Percent of Population Below the Poverty Line

That information can be obtained in census databases. For assessing the bias this variable has on the available ones, we must write $pctpov$ as a linear combination of the variables we do have the data for:

$$
pctpov = \gamma_0 +\gamma_1 \cdot prbarr + \gamma_2 \cdot prbconv + \gamma_3 \cdot prbpris +v
$$

$\gamma_0$ represents the intercept. The other $\gamma_n$ will be the slope coefficient for each of the model variables. We can make some assumptions:

$\beta_7$ (the slope for the pctpov variable for crime rate) has a positive value: the percentage of population below the poverty line will have a positive correlation with the crime rate (poverty might lead to people seeking illegal forms of income)

$\gamma_1$ has a close to zero value: probability of arrest will have very low correlation with the percentage of population below the poverty line (the arrest is related to the evidences available for the police to catch the criminal - in an ideal world)

$\gamma_2$ has a close to zero value: probability of conviction will have very low correlation with the percentage of population below the poverty line (the conviction is related to the nature and the evidences for each crime, not the person commiting it, in a ideal world)

$\gamma_3$ has a positive value: probability of prison will have positive correlation with the percentage of population below the poverty line (in a ideal world, the issuing of a sentence should be only related to the nature of the crime commited, however some judges might consider that a very poor person is more likely to commit a crime again, as means of income, and would be more prone to issuing a sentence with prison time)

$\beta_7$ is positive, and so is $\gamma_3$, however, $\gamma_1$ and $\gamma_2$ are very close to zero. So the ommited variable unemployment rates bias will be positive for $prbconv$. That means that:

$$
\alpha_3 > \beta_3 \\
$$

## Bias Conclusion

By the analysis we have made, the ommited variables impose a positive bias in all the coefficients for the present variables, meaning our model is actually superestimating the correlation between each independent variable and our dependent variable

# Conclusion

<b>We suggest the following</b>
<br/>

* The political campaign should design policies aimed to increase probability of arrest and probability of conviction.  Actionable insights could include:
    + Invest in the police force modernization. The inclusion of cameras in public sites, for example, would increase the probability of arrest and would provide quality evidence to increase the probability of conviction.  
    + Increase the budget  for police force training, this would result in a more efficient and effective police force, therefore increasing the probabilities of arrest and conviction
    + Design policy focused on more stringent arrest protocols and stricter criminal sentencing. 

* Increasing the police per capita ratio or police force size does not decrease crime rate.  This is not very intuitive and we think it could be due to the following reasons:
    + The relationship might be inverse: counties with high crime rates tend to increase their police force, however, that increase is yet to achieve a result in crime reduction.
    + Reporting of crimes: in counties with more police officers, people might feel more inclined to report the crimes, and the higher number of cops might also mean closer police stations for the population to report those crimes. That doesn’t necessarily mean that counties with less police have less crimes: it can also mean that there is a great number of crimes that don’t get reported.
    * It is evident in the third model the effect of young male percent population on crime rate.  The campaign should design crime prevention programs aimed at this demographic group (especially in counties with higher density). 

<b>We suggest further research to include</b>
<br/>

* The data set does not discriminate among crime types.  We suggest that further studies should be done discriminating violent crime (murder, rape, robbery etc.) from minor offenses such as property crimes (burglary, larceny, and auto theft).  This could lead to more interesting findings on the specific effects of the predictor variables per type of crime.  
* The data set only includes data for the year 1987.  We think that this sample could be biased.  We would need to expand this research with more years.
* Adding data on specific percent of young male risk groups, such as school dropouts, teenager parenting, young male substance abuse, could provide more actionable insights to design specific outreach programs. 
