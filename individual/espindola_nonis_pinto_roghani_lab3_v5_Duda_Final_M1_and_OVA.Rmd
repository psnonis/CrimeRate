---
title: 'Is enhancing certainty and severity of punishment associated with reducing crime rate?'
subtitle: 'MIDS W203, Fall 2018, Lab 3'
author: 'Duda Espindola, Pri Nonis, Laura Pintos, Payman Roghani'
output:
  html_document:
    theme: simplex
    highlight: tango
    toc: true
    toc_float: true
    number_sections: true
---

<style>
    body
    {
        text-align: justify
    }
    table > tbody > tr > td
    {
        color: black;
        text-align: right;
        font-family: consolas;
    }
    .table > tbody > tr:nth-child(odd) > td
    {
        background-color: #ffccbc;
        color: black;
    }
    th
    {
        background-color: #dd4814;
        color: white;
    }
    #header,
    #TOC
    {
        text-align: left
    }
</style>


```{r include}
source('../appendix.R')
```

```{r setup, include = FALSE}
import('knitr')
import('kableExtra')
import('tidyverse')
import('RColorBrewer')
import('ggthemes')
import('stargazer')
import('sandwich')
import('car')
import('lmtest')
import('maps')
import('formattable')
import('sparkline')
import('cowplot')
import('corrplot')
import('ggfortify')
import('GGally')

options(digits = 2, message = -1, warning = -1)
opts_chunk$set(fig.width = 9, message = FALSE, warning = FALSE)
```

# Introduction

The primary motivation of this report is to provide causal estimates for determinants of crime in the state of North Carolina. The main aim of our study is to shape the public policy platforms of the political campaign that has hired our services, in the upcoming election cycle. We strive to provide actionable policy recommendations through motivated data analysis of the research question(s).

## Research Question

Our research focuses on the following specific question: <b>Can enhancing the certainty and the severity of punishment reduce the crime rate?</b> We explore how certainty of punishment and severity of punishment within the criminal justice system affects crime. As one of the key goals of the political campaign is to reduce the crime rate, the natural choice for the outcome variable of our study is the Crime Rate variable. We seek to explain the variability of this variable using (1) Probability of Arrests, (2) Probability of Conviction, (3) Probability of Prison, and the (4) Average Prison Sentence. Toughness will be measured by the certainty of punishment based on the first three variables and the severity of punishment based on the fourth. Unfortunately, data for other forms of punishment is not available in our dataset and we will discuss their possible ommited bias on our model(s).

$$
\begin{aligned}
\textbf{Crime Rate} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison} \\
           & + \textbf{Average Prison Sentence}
\end{aligned}
$$

We will primarily use these four explanatory variables as proxies to measure the effects of the the criminal justice system on crime and this relationship will be explored in our first OLS model. However, we expect other variables to have significant secondary effects on this relationship and thus, will further explore their impact in our extended second OLS model. In the third OLS model we will add more variables to the model to gauge the robustness of our choices for regressors.

## Policy Hypothesis

The null hypothesis assumes that the outcome Crime Rate variable is not impacted by the four explanatory variables, Probability of Arrest, Probability of Conviction, Probability of Prison, and Average Prison Sentence. We will test the following hypothesis through our detailed data analysis to justify our ultimate policy recommendation(s).

+ <b>Increasing arrest rates will decrease crime rate</b>
+ <b>Increasing conviction rates will decrease crime rate</b>
+ <b>Increasing prison verdicts will decrease crime rate</b>
+ <b>Increasing prison sentence will decrease crime rate</b>

We will propose recommendations by finding robust, statistically significant, and practically significant regressors from our OLS models. We hope to either reject the null hypothesis by sufficiently explaining the variability of Crime Rate by our explanatory variables or explain why our model may does not support such a conclusion.

# Data Loading and Cleaning

The primary data source for our study is **Cornwell and W. Trumball (1994), Estimating the Economic Model of Crime with Panel Data, Review of Economics and Statistics 76, 360-366**. We will use a single cross-section of data for **1987** from the multi-year panel. (The authors used panel data methods and instrumental variables to control for some types of omitted variables)

The dataset is provided for the year **1987** except for the **Percent Minority** (pctmin), which is provided for 1980.

## Basic Sanity Checks

The dataset contained several technical defects such (1) as empty rows, (2) a duplicated row, and (3) a typo that prevented a numeric variable from being loaded correctly. These issues were easily corrected as shown below.

```{r loading_and_fix}
crime           <- read.csv('crime_v2.csv') # load the dataset
rownames(crime) <- NULL                     # remove row names

crime           <- na.omit(crime)                          # (1) remove empty rows
crime           <- crime[!duplicated(crime$county),]       # (2) remove duplicate row
crime$prbconv   <- as.numeric(as.character(crime$prbconv)) # (3) fix non-numeric value

dim(crime)
```

From the 100 counties of North Carolina our data-set contain a sample of **90** counties. The map below shows the Crime Rate per Capita for the 90 observations; the 10 counties that are not present in the dataset is shown in gray. The dataset contains **25** variables covering the following aspects. The **county** id is a subset of the U.S. Government's FIPS County Code, the full 5-digit code can be constructed by combining the North Carolina FIPS prefix 37 with the **county** id which are the last three digits. For example, 37001 is Almanance County which is the first observation from our dataset with county id of 1.

```{r crime_map}
mSetup(); mMapNC('crmrte', 'Crime Rate per Capita')
```

The missing counties appear to be geographically clustered to the western and eastern sides of North Carolina and gives reason to suspect the sample quality in terms of randomness, with respect to geographical clustering.

## Deeper Analysis

We had to address various anomalies in the dataset, confirming if the values made sense based on the code key and understanding the outlying data points. We used a custom summary table to gleam a high level overview of the data for further analysis. We sorted the variables into four categories as follows.

```{r summary}
crime.summary <- sBuild(crime, crime$crmrte)
```

<b>Variable Categories</b>

+ <b>Identification</b>
```{r var_1, results="asis"}
sTable(crime.summary[c(1,2),]) # Identification
```

+ <b>Crime & Law Enforcement</b>
```{r var_2, results="asis"}
sTable(crime.summary[c(3,4,5,6,7,8),]) # Crime & Law Enforcement
```
+ <b>Demographics & Geography</b>
```{r var_3, results="asis"}
sTable(crime.summary[c(9,10,11,12,13,14,25),]) # Demographics & Geography
```
+ <b>Weekly Wages</b>
```{r var4, results="asis"}
sTable(crime.summary[c(15,16,17,18,19,20,21,22,23),]) # Weekly Wages
```

### Probabilities Above 1

Theoretically speaking, we should not have probabilities over 1 (100%), but that is what we observe in variables Probability of Arrest (prbarr) and Probability of Conviction (prbconv). However, when we understand how those variables were proxied, we realize that they are not actual probabilities: they are simply ratios. 

The probability of arrest is proxied by the ratio between the number of arrests in 1987 to the number of offenses in 1987. However, not every arrest made in 1987 might be referring to offenses made in 1987: there might be arrests referring to crimes committed in previous years, which explains why the ratio between arrests and offenses in 1987 could be above 1.

The probability of conviction is proxied by the ratio between the number of convictions and to the number of arrests in 1987. It is the same thing we have observed for the probability of arrest. The convictions issued in 1987 are not all necessarily referring to arrests made in 1987. Besides that, one arrest might lead to several convictions (example, a person arrested might be convicted for several crimes). In that sense, it is possible for us to have this variable achieving values above 1.

### Outliers Off by Order of Magnitude

Another anomaly we observed, both by the histogram and by the summary statistics, is that for the density variable. There was a single value that is several orders of magnitude lower than other all other observations, with a density of 0.00002. We decided to investigate this further by using third party data sources.

```{r density_check}
crime$county[crime$density<0.0001]
```

Searching for the FIPS code of this county (37173), we see that it is Swain County. When we search the data for Swain County in 1987 in the United States Census Bureau database, we see that the density was in fact 0.202. Further, analysis of the variable indicates that there is a code key error and the density data is in fact **100s of people per sq. mile** and not number of people per sq. mile as it is stated. We corrected the arithmetic error for Swain County's density to bring it in line with the other counties as shown below.

```{r density_fix}
crime$density[crime$county==173]<- crime$density[crime$county==173] * 10000
crime$density[crime$county==173]
```

### Other Significant Outliers

For the Service Industry Weekly Wages, there is one value that stands out as is significantly larger than the next largest value.

```{r service_check}
crime$county[crime$wser>2000]
```

Searching for the FIPS code of this county (37185), we see that it is Warren County. Coincidently only the service sector wages appear to be inflated for this county compared to the average weekly wages of all sectors across North Carolina. It is very likely this value was incorrectly multiplied by 10, and the actual value is 217.7 instead of 2177.1. However, since we cannot confirm that with certainty, we will leave it unmodified and not discard the observation.

# Base Model

## Model Building Process

```{r options, echo = FALSE}
options(digits = 2)
```

The study of the research question requires some exploratory data analysis to choose the correct variables that identify the true relationship we are trying to model. The section below details the process of defining the models.

### Selection of the Outcome Variable

Further analysis beyond our initial EDA is warranted on Crime Rate, the output variable in our study, as implied by our research question. 

In our initial exploration, we noticed that the crime rate histogram showed a positively skewed distribution. A log transformation of the variable pulls the outlying data points closer to the bulk of the observations, resulting in a normal distribution.

```{r outcome_plot, warning = FALSE, fig.align = 'center', fig.width = 9}
p1 <- pHist(    crime$crmrte , breaks = 20, label = "Crime Rate"      )
p2 <- pHist(log(crime$crmrte), breaks = 20, label = "Crime Rate (log)")

plot_grid(p1, p2)
```

More importantly, the log transformation will allow us to interpret changes in the dependent variable as percentages, which is a more meaningful way to describe such changes in this context. Counties have different crime rates and percentage changes in crime will enable county-to-county comparison. As such, we implemented a log transformation on this variable. 

```{r outcome_trans}
crime$crmrte.log <- log(crime$crmrte) # log transformation
```

There is an extreme outlier on the left tail of the data. Upon further investigation, we realize this is county 115 (observation 51), and this very low crime rate might be due to the very low density of the county (below the 1st quartile). For that, we have no reason to suspect the integrity of this datapoint, and leave it as is.

```{r outlier crmrte.log}
crime[crime$crmrte.log < -5,c(1,3,9,26)]
summary(crime$density)
```

### Explanatory Variables

As explained in the introduction, in order to test our hypothesis regarding the impact of the certainty of severe punishment on crime rate, we are using 4 explanatory variables in our base model:

- Probability of Arrest: Defined as the ratio of offenses to arrests. Using this variable, we would like to assess the hypothesis that more stringent arrest protocols and improvements in crime detection would lead to lower crime rate.
- Probability of Conviction: Defined as the ratio of convictions to arrests. If our hypothesis regarding a negative impact of higher convictions/arrests ratio on crime rate is true, then this could lead to highly actionable measures. For instance, stricter sentencing guidelines could implemented, followed by allocation of more resources to law enforcement agencies to collect more effective evidence.
- Probability of Prison: Higher imprisonment rate, as one of the harshest types of criminal sentencing, could have a deterrent effect, leading to lower crime rate. Hence our interest in this variable. 
-Average Sentence Time (Days): Issuing longer sentence times, might affect the perception of the severity of punishment, and inhibit criminal activity. This also a variable that can lead to actionable insights, as it could be possible to change legislations towards longer senteces.

For average sentence time, as to have more interpretable results, we will perform a log transformation, so we can evaluate in terms of percent variation in the average sentence time associated with a percent variation in crime rates.

```{r avgsen_trans}
crime$avgsen.log <- log(crime$avgsen) # log transformation

p1 <- pHist(    crime$avgsen , breaks = 20, label = "Average Sentence"      )
p2 <- pHist(log(crime$avgsen.log), breaks = 20, label = "Average Sentence (log)")

plot_grid(p1, p2)
```

Besides the gain in interpretability, the log transformation in the `avgsen` variable showed an important improve in normality, as observed by the histograms.

Looking at the summary statistics of the 4 variables, we don’t see any alarming issues. Also, histograms show a fairly normal distribution for all 4 variables. Although, there is one extreme outlier in `prbarr`, one in `prbconv` and one not so extreme in `avgsen.log`, which all relate to the same observation, county 115, we decided to keep them in our data because we don’t have any reason to believe that they are erroneous values, and might only be due to the low density of the county (below first quantile). Regarding `prbconv` we also have outliers on counties 185 and 195, and again, those might be due to extreme values of density: low for county 185 (below 1st quartile) and high for county 195 (above 3rd quartile). On the left side, we have an extreme outlier on the probability of prison vairable, at county 173. However, county 173 has the lowest density in our dataset, and that low density could also be the explanation for such a low probability of prison. That said, we will evaluate the influence of these extreme points during or diagnostic analysis of regression models. 


```{r outliers}
crime[crime$prbpris < 0.2 | crime$prbarr>0.9 | crime$prbconv > 1.5,c(1,3,4,5,6,7,9,26,27)]
summary(crime$density)
```

```{r m1_explanatory_plot, warning = FALSE, fig.align = 'center', fig.width = 9}
p1 <- pHist(crime$prbarr,  breaks = 40, label = "Probability of Arrest"    )
p2 <- pHist(crime$prbconv, breaks = 40, label = "Probability of Conviction")
p3 <- pHist(crime$prbpris, breaks = 40, label = "Probability of Prison"    )
p4 <- pHist(crime$avgsen.log, breaks = 40, label ="log Average Sentence Time (Days)")

plot_grid(p1, p2, p3, p4)
```

Next, we looked at the scatterplots of dependent and explanatory variables for our base model. `prbarr`  seems to have a pretty linear relationship with `crmrte.log`. The same with `prbconv`, although we see a curvature towards the right side of the chart. 
`prbpris` does not seem to have a linear relationship with `crmrte.log`, based on the scatterplot; it looks more like a quadratic relationship. However, we decided to leave `prbpris` as is, because a quadratic transformation would make the interpretation of our model unnecessarily complicated. 
`avgsen.log` also points torward a more quadratic relationship with `crmrte.log`, but making such further transformation to the avgsen variable (already logarithmically transformed), will damage the interpretability of our model, so we will leave `avgsen.log` as is.

```{r pScatterMatrix changing parameters}
pScatterMatrix<-function(data, columns)
{
    ggscatmat(data, columns, alpha = 0.5) +
    geom_smooth(method = 'lm', colour = '#dd4814') + theme_wsj()
}
```


```{r m1_correlation, warnings = FALSE, fig.align = "center", fig.width = 9}
pScatterMatrix(crime, columns = c(26,4,5,6,27))
```


## Model Specification

Based on the variables selected, our base population model is:

$$
\begin{aligned}
\textbf{log(Crime Rate)} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison} \\
           & + \textbf{log(Average Sentence)} \\
           & + \textbf{u}
\end{aligned}
$$

```{r m1}
m1 <- lm(crmrte.log ~ prbarr + prbconv + prbpris + avgsen.log, data = crime)
```



### CLM Assumptions

#### Linear in Parameters
    
Our model, per specification, is linear in parameters, as shown above.

#### Random Sampling

We don’t have sufficient insight into how the data have been collected. For example, we don’t know if the probability of arrest is calculated by dividing the number of all arrests by the number all crimes across counties in 1987, or from a sample. Another issue is that we don’t have data from some of counties and we are not sure how including additional data from those counties would affect our analysis, specially since the counties we don't have data for appear to be geographically clustered to the western and estearn sides of North Carolina. As a result, the insights from our regression modelling might not be applicable for the entire North Carolina, unless we have full insight into the missing data.  An additional concern that we have with the sampling is that the data we have is only for year 1987. This specific year is know for the biggest  crash in the stock market in one single day.  If this event created specific conditions like an abnormal number of crime offenses (i.e. due to poverty, depression, anger, etc.) our sample is biased. However, since the data was collected by key government agencies and used for analysis by reputable researchers, we will assume random sampling.


#### No Perfect Multicollinearity

No evidence of perfect collinearity among the model’s explanatory variables was found. Furthermore, R would warn users if such collinearity exists, which did not occur throughout the analysis. This is confirmed by the low variance inflation factor (VIF) scores across model coefficients seen below.

```{r vif m1}
vif(m1)
```

#### Zero Conditional Mean

On the Residual vs Fitted plot we observe there is a curvature in at the red spline curve. Ideally, that line would be flat. This might be due to the fact that we have very few observations on the left side of the chart, however, there is not enough evidence for us to claim we have met the zero conditional mean.


```{r Residuals vs Fitted}
pDiagnostics(m1, which=1)
```

However, even if we don't meet zero conditional mean, for our large sample size (as a rule of thumb, over 30 observations), this condition is relaxed, and it becomes enough to meet exogeneity. By observing the covariance between each predictor variable and our model residuals, we have them very close to zero, meeting the exogeneity condition. 

```{r Exogeneity}
cov(crime$prbarr,m1$residuals)
cov(crime$prbconv, m1$residuals)
cov(crime$prbpris, m1$residuals)
cov(crime$avgsen.log, m1$residuals)
```

#### Homoskedasticity

 Despite the fact that points on chart seem to spread out as we move to the right, there is not strong sign of heteroskedasticity, since we have very few points on the left side. However, the residual from observation row 51 (county 115), has a high influence on our model, with a Cook’s distance between 0.5 and 1.
 
```{r homoeskedasticity}
pDiagnostics(m1, which=3)
plot(m1, which=5)
```
In order to have more certainty on meeting the homoskedasticity assumption, the Breusch-Pagan test was used. As the result p-value <b>`r bptest(m1)$p.value`</b> was greater than 0.05, the null hypothesis (absence of heteroskedasticity) can not be rejected. In other words, there is not enough evidence to claim our model has heteroskedasticity, and therefore, it is safe to assume homoskedasticity.


#### Normality

When we analyze the Q-Q Plot, most points are on, or fairly close to the diagonal line, and simply eyeballing the residuals histogram we also see strong signs of normality.

```{r m11_residuals, fig.align = 'center', fig.width = 9}
p1<- pHist(m1$residuals, breaks = 20, label = "Residuals")
p2<- pDiagnostics(m1, which=2)

p1
p2
```

However, we see a little bit of deviation towards the two ends of the line in the Q-Q plot. Thus, we will use the Shapiro-Wilk test. The result p-value <b>`r shapiro.test(m1$residuals)$p.value`</b> is greater than 0.05, meaning the null hypothesis (that residuals are drawn from a population with normal distribution) can not be rejected. In other words, there is not enough evidence to assume the residuals in our model are not normally distributed. Because of that, we are able assume normality.


### Coefficients Interpretation

```{r m1_test}
coeftest(m1, vcov = vcovHC)
```

While holding all other covariates and unobserved factors fixed:

- $\beta_0$ : `intercept`  is `r coef(m1)[1]`, which can not be interpreted in a meaningful way without considering the other coefficients. The t-stat and p-value on the coefficient indicate that it is statistically significant. The sign of the coefficient and its statistical significance are in line with our research hypothesis. 
- $\beta_1$ : `prbarr`     is `r coef(m1)[2]`, a 1% increase in probability of arrest,     crime rate will go down by approximately `r coef(m1)[2]/100`%. The t-stat and p-value on the coefficient indicate that it is statistically significant. The sign of the coefficient and its statistical significance are in line with our research hypothesis. 
- $\beta_2$ : `prbconv`    is `r coef(m1)[3]`, a 1% increase in probability of conviction, crime rate will go down by approximately `r coef(m1)[3]/100`%. The t-stat and p-value on the coefficient indicate that it is statistically significant. The sign of the coefficient and its statistical significance are in line with our research hypothesis.
- $\beta_3$ : `prbpris`    is `r coef(m1)[4]`, a 1% increase in probability of prison,     crime rate will go up   by approximately `r coef(m1)[4]/100`%. Even though the t-stat and p-value on the coefficient indicate that the coefficient is not statistically significant, its sign is still counter-intuitive and not in line with our hypothesis.
- $\beta_4$ : `avgsen.log` is `r coef(m1)[5]`, a 1% increase in the average sentence,      crime rate will go up   by approximately `r coef(m1)[5]/100`%. Even though the t-stat and p-value on the coefficient indicate that the coefficient is not statistically significant, its sign is still counter-intuitive and not in line with our hypothesis.


It is worth noting that the coefficients for `prbarr` and `prbconv` amplify the effect of increasing `prbarr` or `prbconv`. This is not true for the coefficients for `prbpris` and `avgsen.log`.

Another point worth noting is that, while `prbarr` and `prbconv` behave as we expected, `prbpris` and `avgsen.log` don't: an increase in those variables is associated with an increase in crime rates, the opposite of the effect we expected.

### Goodness of Fit - M1

* The R-squared value for the base model is <b>`r summary(m1)$r.squared`</b>, which means around `r summary(m1)$r.squared*100`% of the variation in crime rate could be explained by our model.
* The adjusted R-square value for the base model is `r summary(m1)$adj.r.squared`, and because it penalizes adding more variables, it is a better comparison indicator for our upcoming models, since the simple R-square can only go up when adding more variables.
* The Akaike Information Criterion value for the base model is <b>`r AIC(m1)`</b>, which we will compare with those of the next models to evaluate goodness of fit.


## Research Interpretation

As evidenced by the coefficients of our base model, we can state that increases in probability of arrest and probability of conviction could potentially lower crime rate. In other words, a policy focused on more stringent arrest protocols and stricter criminal sentencing could be proposed by the political campaign.
The probability of prison has a positive coefficient in our base model, meaning a higher prison to conviction ratio is associated with higher crime rate. We don’t believe this relationship means that, for example, if we increase the probability of prison, the crime rate will go up. We think that this might be due to the fact that the prison to conviction ratio is already high in areas where crime rate is high. For a more effective assessment of such a relationship, we need to have data to observe the trends in crime rate before and after the prison to conviction rate goes up as a result of policy change, which is not currently included in our dataset, which is snapshot of 1987.  An additional possible explanation is that incarceration does not deter crime as it exposes the prisoners to an environment which could amplify their criminal behaviour when they finish their sentence. 
The log of average sentence has a positive coefficient in our base model, meaning issuing higher sentence times on average is associated with higher crime rate. However, we don't believe this means that higher sentence times will drive the crime rate up. We understand this might be due to the nature of our dataset, focused in 1987 only. Maybe areas with higher crime rates simply naturally issued more sentences and higher sentence times, as a measure to inhibit crimes, however, the effect is yet to be noticed in the upcoming years.

# Omitted Variable Analysis

```{r m2}
crime$polpc.log<-log(crime$polpc)
crime$mix.log<-log(crime$mix)
m2 <- lm(crmrte.log ~ prbarr + prbconv + prbpris + avgsen.log+ polpc.log + mix.log, data = crime)
summary(m2)
```

Besides the variables presented to us in the crime dataset, we understand there are other variables that might impact both our explanatory variables and output variable. In this section we will discurr about the effects those variables might have in our model coefficients, theorizing whether their inclusion in the model would drive our coefficients away or closer to zero.

## Illegal Guns per Person (iguns)

This variable aims to measure the ratio of illegal guns to the population of the county. We expect that an increase on the number of illegal guns per person to be associated with a decrease in the probability of arrest, conviction, prison and the average sentence time, since they are harder to track to the owner, and therefore, provide enough evidence for making arrests, issuing convictions and convictions with prison time. Since the illegal purchase of a gun can be interpreted as a counter measure to avoid future punishment, an increase on this variable can be interpreted as an increase on the intent of commiting a crime, thus increasing the crime rates. Going with the same line of thought, an increase in this variable would be also associated with an increase on the mix variable, as crimes commited with guns are face-to-face crimes. However, we don't expect the variation in this variable to be associated with variations in police per capita.

```{r bias table iguns}

bias1<-data.frame(c("prbarr","prbconv","prbpris","avgsen.log","polpc.log", "mix.log"),
                  c("negative","-","-","-","-","-"), 
                  c("-","negative","-","-","-","-"), 
                  c("-","-","positive","-","-","-"),
                  c("-","-","-","positive","-","-"),
                  c("-","-","-","-","positive","-"),
                  c("-","-","-","-","-","positive"),
                  c("positive","positive","positive","positive","positive", "positive"),
                  c("negative","negative","negative","negative","close to zero","positive"),
                  c("negative","negative","negative","negative","close to zero","positive"),
                  c("away from zero","away from zero", "towards zero", "towards zero","close to zero bias","away from zero")
                  )

colnames(bias1)<-c("Regressor","$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$" ,"$\\gamma_1$", "Direction of bias", "Bias wrt zero")

kable(bias1, escape = FALSE)
```

## Average Years of Education (avgeduc)

Based on our background knowledge, we expect that more education will lead to a decrease on crime rates: a more educated population theoretically has better understanding of the law, is more tolerant and have better opportunities, so at least a decrease on pecuniary crimes and hate crimes are expected. By the same logic, more educated people, if commiting a crime, will tend to take some extra precautions in order to not get caught (being cautious in not generating evidence), leading to a decrease in the probability of arrest, probability of conviction, probability of arrest and average sentence time. We don't expect it however to impact police per capita or the mix offenses variables.

```{r bias table avgeduc}

bias2<-data.frame(c("prbarr","prbconv","prbpris","avgsen.log","polpc.log", "mix.log"),
                  c("negative","-","-","-","-","-"), 
                  c("-","negative","-","-","-","-"), 
                  c("-","-","positive","-","-","-"),
                  c("-","-","-","positive","-","-"),
                  c("-","-","-","-","positive","-"),
                  c("-","-","-","-","-","positive"),
                  c("negative","negative","negative","negative","negative", "negative"),
                  c("negative","negative","negative","negative","close to zero","close to zero"),
                  c("positive","positive","positive","positive","close to zero","close to zero"),
                  c("towards zero","towards zero", "away from zero", "away from zero","close to zero bias","close to zero bias")
                  )

colnames(bias2)<-c("Regressor","$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$" ,"$\\gamma_1$", "Direction of bias", "Bias wrt zero")

kable(bias2, escape = FALSE)
```

## Percentage of Population Below the Poverty Line (pctpov)

We expect that higher levels of population below the poverty line might lead to a higher crime rate, as this population, being at risk, might resort to illegal means of income. We expect a positive correlation with probability of arrest, since the line of thought that the extreme poor might be more at risk to resorting to illegality, police may have them in watchlists, making an arrest easier when a crime is comitted by that part of the population. Probability of conviction, probability of prison and average sentence times are also expected to be positevely correlated to poverty, since they might have less access to good defense in courts, and also, judges might understand their condition as a risk factor to crime recidivism, being prone to issuing larger sentence times. We don't expect it however to impact either police per capita or the mix of offenses.

```{r bias table pctpov}

bias3<-data.frame(c("prbarr","prbconv","prbpris","avgsen.log","polpc.log", "mix.log"),
                  c("negative","-","-","-","-","-"), 
                  c("-","negative","-","-","-","-"), 
                  c("-","-","positive","-","-","-"),
                  c("-","-","-","positive","-","-"),
                  c("-","-","-","-","positive","-"),
                  c("-","-","-","-","-","positive"),
                  c("positive","positive","positive","positive","positive", "positive"),
                  c("positive","positive","positive","positive","close to zero","close to zero"),
                  c("positive","positive","positive","positive","close to zero","close to zero"),
                  c("towards zero","towards zero", "away from zero", "away from zero","close to zero bias","close to zero bias")
                  )

colnames(bias3)<-c("Regressor","$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$" ,"$\\gamma_1$", "Direction of bias", "Bias wrt zero")

kable(bias3, escape = FALSE)
```

## Percent of Population Addicted to Alcohol, Drugs or Both (addic)

We understand that a population with higher incidences of substance abuse will tend to have higher crime rates, specially crimes motivated by emotional factors, as intoxicated people may not fully assess the consequences of their actions and react in violent ways. A positive correlation is also expected with probability of arrest and probability of conviction, as crimes commited by intoxicated people might be more related to violent reaction and not premeditaded crimes, and they might not take any measures regarding concealing evidence to avoid getting caught. With more evidence, more likely they are to be arrested and convicted and associated with the nature of the crime comitted, serving prison time, specially if the judge feels the substance abuse might lead them into crime recidivism. We also expect a positive correlation with the average sentence time, as the substance abuse might be considered aggravating circunstances, leading to higher sentence times. We don't expect any relation with police per capita, but we feel there is a positive correlation with the mix offenses variable, since we previously stated that substance abuse might lead to violent reactions, and therefore, increasing the face-to-face offenses.

```{r bias table addic}

bias4<-data.frame(c("prbarr","prbconv","prbpris","avgsen.log","polpc.log", "mix.log"),
                  c("negative","-","-","-","-","-"), 
                  c("-","negative","-","-","-","-"), 
                  c("-","-","positive","-","-","-"),
                  c("-","-","-","positive","-","-"),
                  c("-","-","-","-","positive","-"),
                  c("-","-","-","-","-","positive"),
                  c("positive","positive","positive","positive","positive", "positive"),
                  c("positive","positive","positive","positive","close to zero","positive"),
                  c("positive","positive","positive","positive","close to zero","positive"),
                  c("towards zero","towards zero", "away from zero", "away from zero","close to zero bias","away from zero")
                  )

colnames(bias3)<-c("Regressor","$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$" ,"$\\gamma_1$", "Direction of bias", "Bias wrt zero")

kable(bias4, escape = FALSE)
```