---
title: 'Reducing Crime'
subtitle: 'MIDS W203, Fall 2018, Lab 3'
author: 'Duda Espindola, Pri Nonis, Laura Pintos, Payman Roghani'
output:
    prettydoc::html_pretty:
        theme: architect
        highlight: github
        toc: true
        number_sections: true
---
<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source('assets/utility.R')

import('prettydoc')
import('knitr')
import('kableExtra')
import('tidyverse')
import('RColorBrewer')
import('ggthemes')
import('stargazer')
import('lmtest')
import('maps')
import('summarytools')
import('formattable')
import('sparkline')
import('cowplot')
import('corrplot')

options(digit=3)
```

# Introduction and Research Question

The primary motivation of this report is to provide causal estimates for determinants of crime in the state of North Carolina. The main aim of our study is to shape the public policy platforms, of the political campaign that has hired our services, in the upcoming election cycle. We strive to provide actionable policy recommendations through motivated data analysis of the research question(s).

Our research focuses on the following specific question: <b>Can crime rates be reduced by a tougher criminal justice system?</b> We explore how certainty of punishment and severity of punishment within the criminal justice system affects crime. As one of the key goals of the political campaign is to reduce the crime rate, the natural choice for the outcome variable of our study is the Crime Rate variable. We seek to explain the variability of this variable using Probability of Arrests, Probability of Conviction, and Probability of Prison.

$$
\begin{aligned}
\textbf{Crime Rate} & \sim \textbf{Probability of Arrest} \\
           & + \textbf{Probability of Conviction} \\
           & + \textbf{Probability of Prison}
\end{aligned}
$$

We will primarily use these three explanatory variables as proxies to measure the effects of the the criminal justice system on crime; and this relationship will be explored in our first OLS model. However, we expect other variables to have significant secondary effects on this relationship and will further explore their impact in our extended second OLS model.

## Policy Hypothesis

The null hypothesis assumes that the outcome Crime Rate variable is not impacted by the three explanatory variables Probability of Arrest, Probability of Conviction, and Probability of Prison. We will test the following hypothesis through our detailed data analysis to justify our ultimate policy recommendation(s).

+ <b>Increasing arrest rates will decrease crime rate</b>
+ <b>Increasing conviction rates will decrease crime rate</b>
+ <b>Increasing prison verdicts will decrease crime rate</b>

Our recommendations will be based on sound statistically significant and practically significant results. We hope to reject the null hypothesis by sufficiently explaining the variability of Crime Rate by our explanatory variables. (causal vs associative ..?)

# Data Loading and Cleaning

The primary data source for our study is **Cornwell and W. Trumball (1994), â€œEstimating the Economic Model of Crime with Panel Data, Review of Economics and Statistics 76, 360-366**. We will use a single cross-section of data for **1987** from the multi-year panel. (The authors used panel data methods and instrumental variables to control for some types of omitted variables)

The dataset is provided for the year **1987** except for the **Percent Minority** (pctmin), which is provided for 1980. (Talk about additional datasets we used and why here?)

## Basic Checks

The dataset contained several technical defects such as empty (NA) rows, a duplicated row, and a typo that prevented a numeric variable from being loaded correctly. These issues were easily corrected as shown below.

```{r loading}
crime           <- read.csv('crime_v2.csv')
crime           <- na.omit(crime)
crime           <- crime[!duplicated(crime$county),]
rownames(crime) <- NULL

crime$prbconv   <- as.numeric(as.character(crime$prbconv))
crime.numeric   <- crime[, !names(crime) %in% c('county','year','west','central','urban')]

dim(crime)
```

```{r crimemap, fig.align = 'center', warning = FALSE}
source('assets/maps.R')

map('crmrte', 'Crime Rate per Capita')
```
From the 100 counties of North Carolina our data-set contain a sample of **90** counties. The map above shows the Crime Rate per Capita for the 90 observations; the 10 counties that are not present in the dataset is shown in gray. The dataset contains **25** variables covering the following aspects.

+ <b>Identification</b>
  - county, year
+ <b>Crime & Law Enforcement</b>
  - crmrte, prbarr, prbconv, prbpris, avgsen, polpc, mix
+ <b>Demographics & Geography</b>
  - density, west, central, urban
  - pctmin80, taxpc, pctymle
+ <b>Weekly Wages</b>
  - wcon, wfir, wmfg, wser, wtrd, wtuc
  - wfed, wsta, wloc [government workers]

## Deeper Analysis

We evaluated any other possible oddities with the data, regarding the values it should theoretically assume and understanding its outliers.

```{r summary, echo = FALSE, warning = FALSE, results="asis"}

crime.summary <- tbl_df(t(sapply(3:25, function(n)
{
    x <- crime[,n]
    c(
        Variable = colnames(crime)[n],
        Mean     = round(  mean(x), 2),
        Median   = round(median(x), 2),
        SD       = round(    sd(x), 2),
        Min      = round(   min(x), 2),
        Max      = round(   max(x), 2),
        Boxplot   = list(x),
        Histogram  = list(hist(    x , plot = F)$counts)
    )
})))

formattable(crime.summary, list(
    Boxplot  = function(z)
    {
        sapply(z, function(zz)
        {
            knit(text = sprintf("`r sparkline(c(%s), type='box')`",
                                paste0(zz, collapse = ",")), quiet = TRUE)
        })
    },
    Histogram  = function(z)
    {
        sapply(z, function(zz)
        {
            knit(text = sprintf("`r sparkline(c(%s), type='bar')`",
                                paste0(zz, collapse = ",")), quiet = TRUE)
        })
    }
))
```

### Probabilities above 1

Theoretically speaking, we should not have probabilities over 1 (100%), but that is what we observe in variables Probability of Arrest (prbarr) and Probability of Conviction (prbconv). However, when we understand how those variables were proxied, we realize that they are not actual probabilities: they are simply ratios. 

The probability of arrest is proxied by the ratio between the number of arrests in 1987 to the number of offenses in 1987. However, not every arrest made in 1987 might be referring to offenses made in 1987: there might be arrests referring to crimes commited in previous years, which explains why the ratio between arrests and offenses in 1987 could be above 1.

The probability of conviction is proxied by the ratio between the number of convictions and to the number of arrests in 1987. It is the same thing we have observed for the probability of arrest. The convictions issued in 1987 are not all necessarily referring to arrests made in 1987. Besides that, one arrest might lead to several convictions (example, a person arrested might be convicted for several crimes). In that sense, it is possible for us to have this variable achieving values above 1.

### Outliers in other orders of magnitude

Another thing we observed, both by the histogram and by the summary statistics, is that for the density variable, we have a value that is in a much lower order of magnitude than other observations, with a density of 0.00002. For that, we decide to dig deeper.

```{r Checking the Density}
hist(x = crime$density, breaks=50, main = "Density Distribution", xlab = "Density", ylab = "Frequency")
summary(crime$density)
```

```{r Small Density Value}
crime[crime$density<0.0001,]
```
Searching for the FIPS code of this county (173), we see that it is Swain County. When we search the data for Swain County in 1987 in the United States Census Bureau database, we see that the density was in fact 0.0202. That is clearly an arithmetic error, generating a value a 1000 times smaller. So, we correct it.

```{r Correcting Swain County Density}

crime$density[crime$density<0.0001]<- crime$density[crime$density<0.0001]*1000
crime[crime$county==173,]
```

### Other clear outliers

For the service industry wages, there is one observation in particular that catches the eye, which is way above the second largest value. For that, we take a deeper look

```{r Service Industry Investigation}
crime[crime$wser>2000,]
```

It is county 185, Warren County. The only sector that has a weekly wage so much higher than for the other counties is the service industry, with all other sectors having a weekly wage very close to the state average. One might wonder if this county is particularly attractive for tourism, or some other sort of services, to explain such a difference. That is not the fact: Warren county is a center of tobacco and cotton plantations, and textile mills (https://en.wikipedia.org/wiki/Warren_County,_North_Carolina). It is very likely the value is multiplied by 10, and the actual value is 217.7068 instead of 2177.068. However, since we cannot atest that with certainty, we will leave the value as it is, and will not discard the observation.
